<!DOCTYPE HTML>
<html lang="en"><head><meta name="google-site-verification" content="JagrIsgRHAtLoHnd_ojlWog3u-6KdCst1ndz4MnOuGM" /><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Adhiraj Ghosh</title>
  
  <meta name="author" content="Adhiraj Ghosh">
  <meta name="description" content="Adhiraj Ghosh's academic webiste.">
  <meta name="keywords" content="Adhiraj Ghosh,ML,AI,Computer Vision,Deep Learning,Tuebingen,TÃ¼bingen,Tubingen,ZHAW,SMU,Manipal,RPTM,Reidentification,Irony,Bengali,Germany,Switzerland,Singapore,India,">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ“–</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Adhiraj Ghosh</name>
              </p>
		<p> 
			<b style='color:orange;'>Seeking: Research internships and PhD positions!</b>
	      <p>
		      I am a second-year MSc student in Machine Learning at the University of TÃ¼bingen. I focus my research on multimodal deep learning, especially in the context of Vision-Language Representation Learning. 
		      Currently, I am at <a href="https://bethgelab.org/"> Bethge Lab</a>, working on the holistic understanding of Vision-Language models. 
		      Previously, I worked on visualising figurative speech at the <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/computergrafik/lehrstuhl/">Computer Graphics Group</a>, which led to an Outstanding Paper award at EMNLP 2023.
              </p>
              <p>
                      Before starting my master's, I used to be a Computer Vision Researcher at the Center of Artificial Intelligence,<a href="https://www.zhaw.ch/en/engineering/institutes-centres/cai/">ZHAW</a>, working on domain adaptation in Optical Music Recognition. 
		      I have also worked with <a href="https://scholar.google.com/citations?user=cGClKZkAAAAJ&hl=en">Dr. Daniel Lin Wen-Yan</a> at SMU on feature correspondence-based object tracking. I studied Electrical and Electronics Engineering for my BSc in Manipal/Singapore.
              </p>
	      <p>
                      I am very eager to collaborate on relevant projects, so please reach out if you are interested!
              </p>
              <p style="text-align:center">
                <a href="mailto:adhirajghosh1998@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Adhiraj_Ghosh_Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=t_Q2mvsAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/adhirajghosh/">Github</a> &nbsp/&nbsp
		<a href="https://linkedin.com/in/adhiraj-ghosh/">LinkedIn</a> &nbsp/&nbsp
		<a href="https://bsky.app/profile/adhirajghosh.bsky.social">Bluesky</a> &nbsp/&nbsp
		<a href="https://www.youtube.com/channel/UCHSNLabIVYS4X7SZMz-2KjQ">YouTube</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- NEWS -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;horizontal-align:middle">
                <heading>Recent News</heading>
                <ul>
		<li style="margin: 5px;">Dec 2024 :</strong> New paper on lifelong open-ended benchmarking out on arXiv! </li>
		<li style="margin: 5px;"><strong>Nov 2024 :</strong> Defended my MS thesis! </li>
		<li style="margin: 5px;"><strong>Sep 2024 :</strong> No Zero-shot was accepted at NeurIPS as a poster! Check out coverage by <a href="https://www.youtube.com/watch?v=dDUC-LqVrPU&t=485s">Computerphile</a> and <a href="https://open.spotify.com/episode/6WhMPw3hm7OFapeExwWUDD">AI 'N Stuff</a>! </li>
		<li style="margin: 5px;"><strong>Dec 2023 :</strong> ViPE awarded outstanding paper at EMNLP!</li>
		<li style="margin: 5px;"><strong>Oct 2023 :</strong> ViPE accepted at EMNLP 2023(main conference).</li>
		<a href="javascript:void(0);" onclick="toggleBlock('old_news')">---- show more ----</a>
                  <div id="old_news" style="display: none;">
		<li style="margin: 5px;"><strong>Sep 2023 :</strong> Work on Real World Music Object Recognition published in TISMIR.</li>
                <li style="margin: 5px;"><strong>Mar 2023 :</strong> Started working in the Tubingen AI Centre in Dr. Hendrik Lensch's group.</li>
		<li style="margin: 5px;"><strong>Oct 2022 :</strong> Moved to Germany! Started my MSc at the University of TÃ¼bingen.</li>
		<li style="margin: 5px;"><strong>Aug 2022 :</strong> RPTM accepted for oral presentation at WACV 2023. Check out the <a href="https://openaccess.thecvf.com/content/WACV2023/html/Ghosh_Relation_Preserving_Triplet_Mining_for_Stabilising_the_Triplet_Loss_In_WACV_2023_paper.html">paper</a> and  <a href="https://paperswithcode.com/paper/relation-preserving-triplet-mining-for">SOTA comparisons</a>! </li>
                </div>
                </div></div>
                </ul>
              </td>
            </tr>
        </tbody></table>

	<!-- WORK EXPERIENCE -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Work Experience</heading>
                <p>
		<strong>Mar 2023 - Sep 2023:</strong> Research Assistant at the Computer Graphics group, TÃ¼bingen AI Centre. <br>
		<strong>May 2021 - Aug 2022:</strong> Computer Vision Researcher, ZÃ¼rich University of Applied Sciences. <br>
                <strong>Jan 2020 - Dec 2020:</strong> Visiting Researcher, Singapore Management University <br>
                <strong>Jun 2018 - Aug 2019 :</strong> Undergraduate Research Intern, Jadavpur University. <br>
                </p>
            </td>
                </p>
              </td>
            </tr>
        </tbody></table>

        <!-- PUBLICATIONS -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Publications</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <body>

            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/eccv_pipeline-1.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance </papertitle>
                <br>
                Vishaal Udandarao<sup>*</sup>, Ameya Prabhu<sup>*</sup>, <strong>Adhiraj Ghosh</strong>, Yash Sharma, Philip H.S. Torr, Adel Bibi, Samuel Albanie, Matthias Bethge.
                <br>
                <em>arXiv:2404.04125, 2024</em>
                <br>
		<a href="https://arxiv.org/pdf/2404.04125">Paper </a> /
                <a href="https://github.com/bethgelab/frequency_determines_performance">Code </a> / 
		<a href="https://huggingface.co/datasets/bethgelab/Let-It-Wag">Let It Wag! Benchmark</a>
                <br>
                <p> The impressive empirical performance of VLMs is attributed to test concepts within their pretraining datasets, thus not showcasing "zero-shot" generalization. Instead, they need exponentially more data on a concept to linearly improve performance. </p>
              </td>
            </tr> 
		  
	    <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/vipe.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>ViPE: Visualise Pretty-much Everything </papertitle>
                <br>
                Hassan Shahmohammadi, <strong>Adhiraj Ghosh</strong>, Hendrik Lensch.
                <br>
                <em>EMNLP 2023 <font color="red">(Outstanding Paper Award)</font></em>
                <br>
		<a href="https://aclanthology.org/2023.emnlp-main.333/">Paper </a> /
                <a href="https://github.com/Hazel1994/ViPE">Code </a> / 
		<a href="https://huggingface.co/datasets/fittar/lyric_canvas">Dataset </a> /
		<a href="https://huggingface.co/fittar/ViPE-M-CTX7">HuggingFace </a> / 
		<a href="https://github.com/Hazel1994/ViPE-Videos">Music Videos </a>    
                <br>
                <p> ViPE is the first automated model for translating any arbitrary piece of text into a visualisable prompt. It helps any text-to-image model in figurative or non-lexical language visualisations. </p>
              </td>
            </tr> 

	    <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/tismir.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Real World Music Object Recognition</papertitle>
                <br>
                <strong>Adhiraj Ghosh</strong><sup>*</sup>,Lukas Tuggener<sup>*</sup>, Raphael Emberger<sup>*</sup>, Pascal Sager<sup>*</sup>, et al.
                <br>
                <em>TISMIR 2023</em>
                <br>
		<a href="https://digitalcollection.zhaw.ch/bitstream/11475/28719/1/2023_Tuggener-etal_Real-world-music-object-recognition_TISMIR.pdf">Paper </a> /
                <a href="https://github.com/adhirajghosh/omr-uda">Code </a>
                <br>
                <p> We present solutions to improve recognition accuracy in Music Object Recognition on low-quality, real-world music sheet data and provide confidence-rated model outputs to enable efficient human post-processing. </p>
              </td>
            </tr> 

            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/triplet.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Relation Preserving Triplet Mining for Stabilising the Triplet Loss in Re-identification Systems</papertitle>
                <br>
                <strong>Adhiraj Ghosh</strong>, Kuruparan Shanmugalingam, Wen-Yan Lin
		<br>
                <em>WACV 2023</em>
                <br>
                <a href="https://openaccess.thecvf.com/content/WACV2023/html/Ghosh_Relation_Preserving_Triplet_Mining_for_Stabilising_the_Triplet_Loss_In_WACV_2023_paper.html">Paper </a> /
                <!-- <a href="rptm/rptm.html">Project Page </a> / -->
                <a href="https://github.com/adhirajghosh/RPTM_reid">Code </a> /
                <a href="https://youtu.be/TseV_Hoz2Ms">Video </a> /
                <a href="data/919-wacv-post.pdf">Poster </a>

                <br>
                <p> We propose a new, feature-guided triplet mining scheme for understanding intrinsic pose to solve the intra-class variance problem in re-identification datasets. </p>
              </td>
            </tr> 

            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/bengali.png' width="160">
                </div>
                <script type="text/javascript">
                  function clipnerf_start() {
                    document.getElementById('clipnerf_image').style.opacity = "1";
                  }

                  function clipnerf_stop() {
                    document.getElementById('clipnerf_image').style.opacity = "0";
                  }
                  clipnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Irony Detection in Bengali Tweets: A New Dataset, Experimentation and Results</papertitle>
                <br>
                <strong>Adhiraj Ghosh</strong>, Kamal Sarkar
                <br>
                <em>ICCIDS 2020</em>
                <br>
                <a href="https://link.springer.com/chapter/10.1007/978-3-030-63467-4_9">Paper </a> /
                <a href="data/ju_irony.rar">Dataset</a>
                <p></p>
                <p> This paper presents the description of the Bengali irony detection dataset developed by us and reports results obtained on our Bengali irony dataset using SOTA machine learning methodologies. </p>
              </td>
            </tr>
<!-- 
        </tbody> </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <p style="text-align:center;font-size:small;"> Design and code from <a href="https://jonbarron.info/"> Jon Barron's website</a></p>
              </td>
            </tr>
          </tbody>
        </table> -->
      </td>
    </tr>
  </table>
</body>
<center><a href='https://clustrmaps.com/site/1budp'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=400&t=tt&d=SJR_sBjcwKN6nIp21umiUWKBrYKCj0ypdEA0rlAl0tg&co=2d78ad&ct=ffffff'/></a></center>
</html>
